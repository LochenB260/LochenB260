import requests
from bs4 import BeautifulSoup
from collections import deque
 
def bfs_crawl(start_url):
    visited = set()
    queue = deque([start_url])
    while queue:
        url = queue.popleft()
        if url in visited:
            continue
        visited.add(url)
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')
        print(f'Crawled: {url}')
        for link in soup.find_all('a', href=True):
            next_url = link['href']
            if next_url.startswith('http') and next_url not in visited:
                queue.append(next_url)
 
start_url = 'http://example.com'
bfs_crawl(start_url)
